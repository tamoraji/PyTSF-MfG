{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T01:08:02.042033Z",
     "start_time": "2024-10-30T01:08:01.401825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "file_path = '/Users/moji/PyTSF-MfG/data/MWTP_Elec_Daily.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ],
   "id": "8b4ba9c861bf7ddd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            date     kwh1    kw1  kwh2  kw2  billed_kwh  solar_kwh  total_kwh  \\\n",
       "0     01/01/2010  13014.0  758.4   0.0  0.0     13014.0      0.000    13014.0   \n",
       "1     01/02/2010  14058.0  811.2   0.0  0.0     14058.0      0.000    14058.0   \n",
       "2     01/03/2010  14560.8  842.4   0.0  0.0     14560.8      0.000    14560.8   \n",
       "3     01/04/2010  14814.0  756.0   0.0  0.0     14814.0      0.000    14814.0   \n",
       "4     01/05/2010  15052.8  777.6   0.0  0.0     15052.8      0.000    15052.8   \n",
       "...          ...      ...    ...   ...  ...         ...        ...        ...   \n",
       "5352  08/27/2024  16311.6  792.0   0.0  0.0     16311.6    758.367    17070.0   \n",
       "5353  08/28/2024  16780.8  763.2   0.0  0.0     16780.8    695.311    17476.1   \n",
       "5354  08/29/2024  15290.4  768.0   0.0  0.0     15290.4    644.772    15935.2   \n",
       "5355  08/30/2024  16218.0  756.0   0.0  0.0     16218.0    637.378    16855.4   \n",
       "5356  08/31/2024  14204.4  794.4   0.0  0.0     14204.4    536.011    14740.4   \n",
       "\n",
       "      mg_finish  \n",
       "0     11.670000  \n",
       "1     11.740000  \n",
       "2     13.150000  \n",
       "3     12.950000  \n",
       "4     13.070000  \n",
       "...         ...  \n",
       "5352  18.859375  \n",
       "5353  19.078125  \n",
       "5354  17.328125  \n",
       "5355  18.562500  \n",
       "5356  15.531250  \n",
       "\n",
       "[5357 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>kwh1</th>\n",
       "      <th>kw1</th>\n",
       "      <th>kwh2</th>\n",
       "      <th>kw2</th>\n",
       "      <th>billed_kwh</th>\n",
       "      <th>solar_kwh</th>\n",
       "      <th>total_kwh</th>\n",
       "      <th>mg_finish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2010</td>\n",
       "      <td>13014.0</td>\n",
       "      <td>758.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13014.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13014.0</td>\n",
       "      <td>11.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/02/2010</td>\n",
       "      <td>14058.0</td>\n",
       "      <td>811.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14058.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14058.0</td>\n",
       "      <td>11.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/03/2010</td>\n",
       "      <td>14560.8</td>\n",
       "      <td>842.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14560.8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14560.8</td>\n",
       "      <td>13.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/04/2010</td>\n",
       "      <td>14814.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14814.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14814.0</td>\n",
       "      <td>12.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/05/2010</td>\n",
       "      <td>15052.8</td>\n",
       "      <td>777.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15052.8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>15052.8</td>\n",
       "      <td>13.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5352</th>\n",
       "      <td>08/27/2024</td>\n",
       "      <td>16311.6</td>\n",
       "      <td>792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16311.6</td>\n",
       "      <td>758.367</td>\n",
       "      <td>17070.0</td>\n",
       "      <td>18.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5353</th>\n",
       "      <td>08/28/2024</td>\n",
       "      <td>16780.8</td>\n",
       "      <td>763.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16780.8</td>\n",
       "      <td>695.311</td>\n",
       "      <td>17476.1</td>\n",
       "      <td>19.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5354</th>\n",
       "      <td>08/29/2024</td>\n",
       "      <td>15290.4</td>\n",
       "      <td>768.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15290.4</td>\n",
       "      <td>644.772</td>\n",
       "      <td>15935.2</td>\n",
       "      <td>17.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5355</th>\n",
       "      <td>08/30/2024</td>\n",
       "      <td>16218.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16218.0</td>\n",
       "      <td>637.378</td>\n",
       "      <td>16855.4</td>\n",
       "      <td>18.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5356</th>\n",
       "      <td>08/31/2024</td>\n",
       "      <td>14204.4</td>\n",
       "      <td>794.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14204.4</td>\n",
       "      <td>536.011</td>\n",
       "      <td>14740.4</td>\n",
       "      <td>15.531250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5357 rows Ã— 9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T01:08:11.421299Z",
     "start_time": "2024-10-30T01:08:11.412721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset info:\")\n",
    "print(df.info())"
   ],
   "id": "ae3fb51fb2b8d7f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5357 entries, 0 to 5356\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date        5357 non-null   object \n",
      " 1   kwh1        5357 non-null   float64\n",
      " 2   kw1         5356 non-null   float64\n",
      " 3   kwh2        5357 non-null   float64\n",
      " 4   kw2         5357 non-null   float64\n",
      " 5   billed_kwh  5356 non-null   float64\n",
      " 6   solar_kwh   5357 non-null   float64\n",
      " 7   total_kwh   5357 non-null   float64\n",
      " 8   mg_finish   5357 non-null   float64\n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 376.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T01:08:40.544575Z",
     "start_time": "2024-10-30T01:08:40.530503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nDataset head:\")\n",
    "print(df.head())\n",
    "# Check for duplicate timestamps\n",
    "duplicates = df[df.duplicated(subset=['date'], keep=False)]\n",
    "print(f\"\\nNumber of rows with duplicate timestamps: {len(duplicates)}\")\n"
   ],
   "id": "560e730a9d66e621",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset head:\n",
      "         date     kwh1    kw1  kwh2  kw2  billed_kwh  solar_kwh  total_kwh  \\\n",
      "0  01/01/2010  13014.0  758.4   0.0  0.0     13014.0        0.0    13014.0   \n",
      "1  01/02/2010  14058.0  811.2   0.0  0.0     14058.0        0.0    14058.0   \n",
      "2  01/03/2010  14560.8  842.4   0.0  0.0     14560.8        0.0    14560.8   \n",
      "3  01/04/2010  14814.0  756.0   0.0  0.0     14814.0        0.0    14814.0   \n",
      "4  01/05/2010  15052.8  777.6   0.0  0.0     15052.8        0.0    15052.8   \n",
      "\n",
      "   mg_finish  \n",
      "0      11.67  \n",
      "1      11.74  \n",
      "2      13.15  \n",
      "3      12.95  \n",
      "4      13.07  \n",
      "\n",
      "Number of rows with duplicate timestamps: 0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T01:09:18.701566Z",
     "start_time": "2024-10-30T01:09:18.695924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if len(duplicates) > 0:\n",
    "    print(\"\\nSample of duplicate timestamps:\")\n",
    "    print(duplicates.head(10))  # Show first 10 duplicates\n",
    "\n",
    "    # Option 1: Keep the first occurrence of each timestamp\n",
    "    df_deduped = df.drop_duplicates(subset=['date'], keep='first')\n",
    "\n",
    "    # Option 2: Aggregate data for duplicate timestamps (e.g., taking the mean)\n",
    "    # df_deduped = df.groupby(['unique_id', 'ds'])['y'].mean().reset_index()\n",
    "\n",
    "    print(f\"\\nShape of dataset after deduplication: {df_deduped.shape}\")\n",
    "\n",
    "    # Check if deduplication resolved the issue\n",
    "    if df_deduped['Date_Time'].is_unique:\n",
    "        print(\"Deduplication successful. Timestamps are now unique.\")\n",
    "    else:\n",
    "        print(\"Deduplication did not resolve all duplicates. Further investigation needed.\")\n",
    "\n",
    "    # # Save the deduplicated dataset\n",
    "    # output_path = '/Users/moji/PyTSF-MfG/data/deduplicated_dataset.csv'  # Replace with your desired output path\n",
    "    # df_deduped.to_csv(output_path, index_label='id')\n",
    "    # print(f\"\\nDeduplicated dataset saved as: {output_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"No duplicate timestamps found. The issue may be elsewhere.\")"
   ],
   "id": "c60447b5d6fb02d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate timestamps found. The issue may be elsewhere.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "# Make an explicit copy to ensure we're working with a new DataFrame\n",
    "df_deduped = df_deduped.copy()\n",
    "\n",
    "print(\"\\nDate range:\")\n",
    "print(f\"Start: {df_deduped['date'].min()}\")\n",
    "print(f\"End: {df_deduped['date'].max()}\")\n",
    "\n",
    "# Convert 'Date_Time' to datetime using .loc\n",
    "df_deduped.loc[:, 'date'] = pd.to_datetime(df_deduped['date'], format='%m-%d-%Y')\n",
    "\n",
    "# Check for any inconsistencies in the time intervals\n",
    "time_diff = df_deduped['date'].diff()\n",
    "inconsistent_intervals = time_diff[time_diff != pd.Timedelta(minutes=15)]\n",
    "if not inconsistent_intervals.empty:\n",
    "    print(\"\\nInconsistent time intervals found:\")\n",
    "    print(inconsistent_intervals.head())\n",
    "else:\n",
    "    print(\"\\nAll time intervals are consistent (15 minutes).\")"
   ],
   "id": "e4846946caf66c59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T01:16:55.590056Z",
     "start_time": "2024-10-30T01:16:55.495037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "df = df.copy()\n",
    "# Convert 'Date' column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y')\n",
    "# Set 'Date' as the index\n",
    "df.set_index('date', inplace=True)\n",
    "# Sort the index to ensure chronological order\n",
    "df.sort_index(inplace=True)\n",
    "# Create a complete date range including weekends\n",
    "date_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='D')\n",
    "# Reindex the dataframe with the complete date range\n",
    "df_reindexed = df.reindex(date_range)\n",
    "# Check for missing values after reindexing\n",
    "print(\"Missing values after reindexing (including weekends):\")\n",
    "print(df_reindexed.isnull().sum())\n",
    "# Interpolate missing values\n",
    "df_interpolated = df_reindexed.interpolate(method='time')\n",
    "# Check for missing values after interpolation\n",
    "print(\"\\nMissing values after interpolation:\")\n",
    "print(df_interpolated.isnull().sum())\n",
    "# Fill any remaining NaN values at the beginning or end with the nearest valid value\n",
    "df_interpolated = df_interpolated.fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "# Save the new dataset without missing values\n",
    "output_path = '/Users/moji/PyTSF-MfG/data/new_dataset.csv'\n",
    "df_interpolated.to_csv(output_path)\n",
    "print(f\"\\nNew dataset saved as '{output_path}'\")\n",
    "\n",
    "# Display the first few rows of the interpolated dataset\n",
    "print(\"\\nFirst few rows of the interpolated dataset:\")\n",
    "print(df_interpolated.head())\n",
    "\n",
    "# Display basic statistics of the interpolated dataset\n",
    "print(\"\\nBasic statistics of the interpolated dataset:\")\n",
    "print(df_interpolated.describe())"
   ],
   "id": "f029851624477495",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after reindexing (including weekends):\n",
      "kwh1          0\n",
      "kw1           1\n",
      "kwh2          0\n",
      "kw2           0\n",
      "billed_kwh    1\n",
      "solar_kwh     0\n",
      "total_kwh     0\n",
      "mg_finish     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after interpolation:\n",
      "kwh1          0\n",
      "kw1           0\n",
      "kwh2          0\n",
      "kw2           0\n",
      "billed_kwh    0\n",
      "solar_kwh     0\n",
      "total_kwh     0\n",
      "mg_finish     0\n",
      "dtype: int64\n",
      "\n",
      "New dataset saved as '/Users/moji/PyTSF-MfG/data/new_dataset.csv'\n",
      "\n",
      "First few rows of the interpolated dataset:\n",
      "               kwh1    kw1  kwh2  kw2  billed_kwh  solar_kwh  total_kwh  \\\n",
      "2010-01-01  13014.0  758.4   0.0  0.0     13014.0        0.0    13014.0   \n",
      "2010-01-02  14058.0  811.2   0.0  0.0     14058.0        0.0    14058.0   \n",
      "2010-01-03  14560.8  842.4   0.0  0.0     14560.8        0.0    14560.8   \n",
      "2010-01-04  14814.0  756.0   0.0  0.0     14814.0        0.0    14814.0   \n",
      "2010-01-05  15052.8  777.6   0.0  0.0     15052.8        0.0    15052.8   \n",
      "\n",
      "            mg_finish  \n",
      "2010-01-01      11.67  \n",
      "2010-01-02      11.74  \n",
      "2010-01-03      13.15  \n",
      "2010-01-04      12.95  \n",
      "2010-01-05      13.07  \n",
      "\n",
      "Basic statistics of the interpolated dataset:\n",
      "               kwh1          kw1         kwh2          kw2    billed_kwh  \\\n",
      "count   5357.000000  5357.000000  5357.000000  5357.000000   5357.000000   \n",
      "mean   13713.881389   684.783573   658.407019    45.575135  14372.387866   \n",
      "std     1796.968653   108.373821   642.806609    40.549771   1767.269811   \n",
      "min        0.000000     0.000000     0.000000     0.000000    632.400000   \n",
      "25%    12564.000000   614.400000     0.000000     0.000000  13185.600000   \n",
      "50%    13560.000000   660.000000   481.200000    43.200000  14271.600000   \n",
      "75%    14604.000000   732.000000  1002.000000    67.200000  15375.600000   \n",
      "max    24043.200000  1159.200000  8919.600000   636.000000  24043.200000   \n",
      "\n",
      "         solar_kwh     total_kwh    mg_finish  \n",
      "count  5357.000000   5357.000000  5357.000000  \n",
      "mean    132.146017  14504.434349    14.311939  \n",
      "std     260.989508   1732.692573     1.597423  \n",
      "min     -14.727030    637.200000     6.670000  \n",
      "25%       0.000000  13335.600000    13.340000  \n",
      "50%       0.000000  14420.400000    14.125000  \n",
      "75%      84.156000  15469.200000    15.090000  \n",
      "max    1140.305000  24043.200000    22.770000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0s/whfbkk11083fmvg1wl2nrqqm0000gn/T/ipykernel_98377/3610453067.py:22: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_interpolated = df_interpolated.fillna(method='bfill').fillna(method='ffill')\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_path = '/Users/moji/PyTSF-MfG/data'\n",
    "datasets = load_datasets_statforecast_uni(data_path)"
   ],
   "id": "c12cfcbb08468ffe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/moji/PyTSF-MfG/data/BrentOilPrices.csv')\n",
    "# Convert 'Date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='mixed')\n",
    "# Set 'Date' as the index\n",
    "df.set_index('Date', inplace=True)\n",
    "# Sort the index to ensure chronological order\n",
    "df.sort_index(inplace=True)\n",
    "# Create a complete date range including weekends\n",
    "date_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='D')\n",
    "# Reindex the dataframe with the complete date range\n",
    "df_reindexed = df.reindex(date_range)\n",
    "# Check for missing values after reindexing\n",
    "print(\"Missing values after reindexing (including weekends):\")\n",
    "print(df_reindexed.isnull().sum())\n",
    "# Interpolate missing values\n",
    "df_interpolated = df_reindexed.interpolate(method='time')\n",
    "# Check for missing values after interpolation\n",
    "print(\"\\nMissing values after interpolation:\")\n",
    "print(df_interpolated.isnull().sum())\n",
    "# Fill any remaining NaN values at the beginning or end with the nearest valid value\n",
    "df_interpolated = df_interpolated.fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "# Save the new dataset without missing values\n",
    "output_path = '/Users/moji/PyTSF-MfG/data/BrentOilPrices_Interpolated.csv'\n",
    "df_interpolated.to_csv(output_path)\n",
    "print(f\"\\nNew dataset saved as '{output_path}'\")\n",
    "\n",
    "# Display the first few rows of the interpolated dataset\n",
    "print(\"\\nFirst few rows of the interpolated dataset:\")\n",
    "print(df_interpolated.head())\n",
    "\n",
    "# Display basic statistics of the interpolated dataset\n",
    "print(\"\\nBasic statistics of the interpolated dataset:\")\n",
    "print(df_interpolated.describe())"
   ],
   "id": "8bce8c25950025bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/moji/PyTSF-MfG/data/ISO-NY_Central.csv')\n",
    "print(df.shape)\n",
    "# Convert 'Time_Stamp' column to datetime\n",
    "df['Time_Stamp'] = pd.to_datetime(df['Time_Stamp'])\n",
    "\n",
    "# Set 'Time_Stamp' as the index\n",
    "df.set_index('Time_Stamp', inplace=True)\n",
    "\n",
    "# Sort the index to ensure chronological order\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# Create a complete time range with 15-minute intervals\n",
    "time_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='15min')\n",
    "\n",
    "# Reindex the dataframe with the complete time range\n",
    "df_reindexed = df.reindex(time_range)\n",
    "print(df_reindexed.shape)\n",
    "# Check for missing values after reindexing\n",
    "print(\"Missing values after reindexing:\")\n",
    "print(df_reindexed.isnull().sum())\n",
    "# Interpolate missing values\n",
    "df_interpolated = df_reindexed.interpolate(method='time')\n",
    "# Check for missing values after interpolation\n",
    "print(\"\\nMissing values after interpolation:\")\n",
    "print(df_interpolated.isnull().sum())\n",
    "# Fill any remaining NaN values at the beginning or end with the nearest valid value\n",
    "df_interpolated = df_interpolated.fillna(method='bfill').fillna(method='ffill')\n",
    "# Final check for missing values\n",
    "print(\"\\nFinal check for missing values:\")\n",
    "print(df_interpolated.isnull().sum())\n",
    "\n",
    "# Save the new dataset without missing values\n",
    "output_path = '/Users/moji/PyTSF-MfG/data/LoadData_Interpolated.csv'\n",
    "df_interpolated.to_csv(output_path)\n",
    "\n",
    "print(f\"\\nNew dataset saved as '{output_path}'\")\n",
    "\n",
    "# Display the first few rows of the interpolated dataset\n",
    "print(\"\\nFirst few rows of the interpolated dataset:\")\n",
    "print(df_interpolated.head())\n",
    "\n",
    "# Display basic statistics of the interpolated dataset\n",
    "print(\"\\nBasic statistics of the interpolated dataset:\")\n",
    "print(df_interpolated.describe())\n",
    "# Check for any gaps in the time series\n",
    "time_diff = df_interpolated.index.to_series().diff()\n",
    "gaps = time_diff[time_diff > pd.Timedelta(minutes=15)]\n",
    "if not gaps.empty:\n",
    "    print(\"\\nGaps found in the time series:\")\n",
    "    print(gaps)\n",
    "else:\n",
    "    print(\"\\nNo gaps found in the time series.\")"
   ],
   "id": "c126774d1b692bb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "e4e1b64839e32b10",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
