{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "file_path = '/Users/moji/PyTSF-MfG/data/Steel_industry2.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ],
   "id": "8b4ba9c861bf7ddd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset info:\")\n",
    "print(df.info())"
   ],
   "id": "ae3fb51fb2b8d7f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\nDataset head:\")\n",
    "print(df.head())\n",
    "# Check for duplicate timestamps\n",
    "duplicates = df[df.duplicated(subset=['Date_Time'], keep=False)]\n",
    "print(f\"\\nNumber of rows with duplicate timestamps: {len(duplicates)}\")\n"
   ],
   "id": "560e730a9d66e621",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if len(duplicates) > 0:\n",
    "    print(\"\\nSample of duplicate timestamps:\")\n",
    "    print(duplicates.head(10))  # Show first 10 duplicates\n",
    "\n",
    "    # Option 1: Keep the first occurrence of each timestamp\n",
    "    df_deduped = df.drop_duplicates(subset=['Date_Time'], keep='first')\n",
    "\n",
    "    # Option 2: Aggregate data for duplicate timestamps (e.g., taking the mean)\n",
    "    # df_deduped = df.groupby(['unique_id', 'ds'])['y'].mean().reset_index()\n",
    "\n",
    "    print(f\"\\nShape of dataset after deduplication: {df_deduped.shape}\")\n",
    "\n",
    "    # Check if deduplication resolved the issue\n",
    "    if df_deduped['Date_Time'].is_unique:\n",
    "        print(\"Deduplication successful. Timestamps are now unique.\")\n",
    "    else:\n",
    "        print(\"Deduplication did not resolve all duplicates. Further investigation needed.\")\n",
    "\n",
    "    # # Save the deduplicated dataset\n",
    "    # output_path = '/Users/moji/PyTSF-MfG/data/deduplicated_dataset.csv'  # Replace with your desired output path\n",
    "    # df_deduped.to_csv(output_path, index_label='id')\n",
    "    # print(f\"\\nDeduplicated dataset saved as: {output_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"No duplicate timestamps found. The issue may be elsewhere.\")"
   ],
   "id": "c60447b5d6fb02d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "# Make an explicit copy to ensure we're working with a new DataFrame\n",
    "df_deduped = df_deduped.copy()\n",
    "\n",
    "print(\"\\nDate range:\")\n",
    "print(f\"Start: {df_deduped['Date_Time'].min()}\")\n",
    "print(f\"End: {df_deduped['Date_Time'].max()}\")\n",
    "\n",
    "# Convert 'Date_Time' to datetime using .loc\n",
    "df_deduped.loc[:, 'Date_Time'] = pd.to_datetime(df_deduped['Date_Time'], format='%d-%m-%Y %H:%M')\n",
    "\n",
    "# Check for any inconsistencies in the time intervals\n",
    "time_diff = df_deduped['Date_Time'].diff()\n",
    "inconsistent_intervals = time_diff[time_diff != pd.Timedelta(minutes=15)]\n",
    "if not inconsistent_intervals.empty:\n",
    "    print(\"\\nInconsistent time intervals found:\")\n",
    "    print(inconsistent_intervals.head())\n",
    "else:\n",
    "    print(\"\\nAll time intervals are consistent (15 minutes).\")"
   ],
   "id": "e4846946caf66c59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "df = df_deduped.copy()\n",
    "# Convert 'Date' column to datetime\n",
    "df['Date_Time'] = pd.to_datetime(df['Date_Time'], format='%d-%m-%Y %H:%M')\n",
    "# Set 'Date' as the index\n",
    "df.set_index('Date_Time', inplace=True)\n",
    "# Sort the index to ensure chronological order\n",
    "df.sort_index(inplace=True)\n",
    "# Create a complete date range including weekends\n",
    "date_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='15min')\n",
    "# Reindex the dataframe with the complete date range\n",
    "df_reindexed = df.reindex(date_range)\n",
    "# Check for missing values after reindexing\n",
    "print(\"Missing values after reindexing (including weekends):\")\n",
    "print(df_reindexed.isnull().sum())\n",
    "# Interpolate missing values\n",
    "df_interpolated = df_reindexed.interpolate(method='time')\n",
    "# Check for missing values after interpolation\n",
    "print(\"\\nMissing values after interpolation:\")\n",
    "print(df_interpolated.isnull().sum())\n",
    "# Fill any remaining NaN values at the beginning or end with the nearest valid value\n",
    "df_interpolated = df_interpolated.fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "# Save the new dataset without missing values\n",
    "output_path = '/Users/moji/PyTSF-MfG/data/steel_Interpolated.csv'\n",
    "df_interpolated.to_csv(output_path)\n",
    "print(f\"\\nNew dataset saved as '{output_path}'\")\n",
    "\n",
    "# Display the first few rows of the interpolated dataset\n",
    "print(\"\\nFirst few rows of the interpolated dataset:\")\n",
    "print(df_interpolated.head())\n",
    "\n",
    "# Display basic statistics of the interpolated dataset\n",
    "print(\"\\nBasic statistics of the interpolated dataset:\")\n",
    "print(df_interpolated.describe())"
   ],
   "id": "f029851624477495",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_path = '/Users/moji/PyTSF-MfG/data'\n",
    "datasets = load_datasets_statforecast_uni(data_path)"
   ],
   "id": "c12cfcbb08468ffe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/moji/PyTSF-MfG/data/BrentOilPrices.csv')\n",
    "# Convert 'Date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='mixed')\n",
    "# Set 'Date' as the index\n",
    "df.set_index('Date', inplace=True)\n",
    "# Sort the index to ensure chronological order\n",
    "df.sort_index(inplace=True)\n",
    "# Create a complete date range including weekends\n",
    "date_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='D')\n",
    "# Reindex the dataframe with the complete date range\n",
    "df_reindexed = df.reindex(date_range)\n",
    "# Check for missing values after reindexing\n",
    "print(\"Missing values after reindexing (including weekends):\")\n",
    "print(df_reindexed.isnull().sum())\n",
    "# Interpolate missing values\n",
    "df_interpolated = df_reindexed.interpolate(method='time')\n",
    "# Check for missing values after interpolation\n",
    "print(\"\\nMissing values after interpolation:\")\n",
    "print(df_interpolated.isnull().sum())\n",
    "# Fill any remaining NaN values at the beginning or end with the nearest valid value\n",
    "df_interpolated = df_interpolated.fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "# Save the new dataset without missing values\n",
    "output_path = '/Users/moji/PyTSF-MfG/data/BrentOilPrices_Interpolated.csv'\n",
    "df_interpolated.to_csv(output_path)\n",
    "print(f\"\\nNew dataset saved as '{output_path}'\")\n",
    "\n",
    "# Display the first few rows of the interpolated dataset\n",
    "print(\"\\nFirst few rows of the interpolated dataset:\")\n",
    "print(df_interpolated.head())\n",
    "\n",
    "# Display basic statistics of the interpolated dataset\n",
    "print(\"\\nBasic statistics of the interpolated dataset:\")\n",
    "print(df_interpolated.describe())"
   ],
   "id": "8bce8c25950025bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/moji/PyTSF-MfG/data/ISO-NY_Central.csv')\n",
    "print(df.shape)\n",
    "# Convert 'Time_Stamp' column to datetime\n",
    "df['Time_Stamp'] = pd.to_datetime(df['Time_Stamp'])\n",
    "\n",
    "# Set 'Time_Stamp' as the index\n",
    "df.set_index('Time_Stamp', inplace=True)\n",
    "\n",
    "# Sort the index to ensure chronological order\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# Create a complete time range with 15-minute intervals\n",
    "time_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='15min')\n",
    "\n",
    "# Reindex the dataframe with the complete time range\n",
    "df_reindexed = df.reindex(time_range)\n",
    "print(df_reindexed.shape)\n",
    "# Check for missing values after reindexing\n",
    "print(\"Missing values after reindexing:\")\n",
    "print(df_reindexed.isnull().sum())\n",
    "# Interpolate missing values\n",
    "df_interpolated = df_reindexed.interpolate(method='time')\n",
    "# Check for missing values after interpolation\n",
    "print(\"\\nMissing values after interpolation:\")\n",
    "print(df_interpolated.isnull().sum())\n",
    "# Fill any remaining NaN values at the beginning or end with the nearest valid value\n",
    "df_interpolated = df_interpolated.fillna(method='bfill').fillna(method='ffill')\n",
    "# Final check for missing values\n",
    "print(\"\\nFinal check for missing values:\")\n",
    "print(df_interpolated.isnull().sum())\n",
    "\n",
    "# Save the new dataset without missing values\n",
    "output_path = '/Users/moji/PyTSF-MfG/data/LoadData_Interpolated.csv'\n",
    "df_interpolated.to_csv(output_path)\n",
    "\n",
    "print(f\"\\nNew dataset saved as '{output_path}'\")\n",
    "\n",
    "# Display the first few rows of the interpolated dataset\n",
    "print(\"\\nFirst few rows of the interpolated dataset:\")\n",
    "print(df_interpolated.head())\n",
    "\n",
    "# Display basic statistics of the interpolated dataset\n",
    "print(\"\\nBasic statistics of the interpolated dataset:\")\n",
    "print(df_interpolated.describe())\n",
    "# Check for any gaps in the time series\n",
    "time_diff = df_interpolated.index.to_series().diff()\n",
    "gaps = time_diff[time_diff > pd.Timedelta(minutes=15)]\n",
    "if not gaps.empty:\n",
    "    print(\"\\nGaps found in the time series:\")\n",
    "    print(gaps)\n",
    "else:\n",
    "    print(\"\\nNo gaps found in the time series.\")"
   ],
   "id": "c126774d1b692bb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "e4e1b64839e32b10",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
