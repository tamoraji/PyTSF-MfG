{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T00:43:04.624295Z",
     "start_time": "2024-10-01T00:43:03.794379Z"
    }
   },
   "source": "from modules.utils import load_datasets_statforecast_uni",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T00:43:05.979874Z",
     "start_time": "2024-10-01T00:43:05.277386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = '/Users/moji/PyTSF-MfG/data'\n",
    "datasets = load_datasets_statforecast_uni(data_path)"
   ],
   "id": "d65d8480f0b433ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset: air_passengers\n",
      "File path: /Users/moji/PyTSF-MfG/data/AirPassengers.csv\n",
      "Warning: Could not infer consistent date format for column 'Month'. Falling back to flexible parsing, which may be slow and inconsistent.\n",
      "Date parsing complete for air_passengers\n",
      "Dataset shape for air_passengers: (144, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144 entries, 0 to 143\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   unique_id  144 non-null    object        \n",
      " 1   ds         144 non-null    datetime64[ns]\n",
      " 2   y          144 non-null    int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(1)\n",
      "memory usage: 3.5+ KB\n",
      "None\n",
      "    unique_id         ds    y\n",
      "0  Passengers 1949-01-01  112\n",
      "1  Passengers 1949-02-01  118\n",
      "2  Passengers 1949-03-01  132\n",
      "3  Passengers 1949-04-01  129\n",
      "4  Passengers 1949-05-01  121\n",
      "Most common time difference: 31 days 00:00:00\n",
      "\n",
      "Loading dataset: ETTh1\n",
      "File path: /Users/moji/PyTSF-MfG/data/ETTh1.csv\n",
      "Date parsing complete for ETTh1\n",
      "Dataset shape for ETTh1: (17420, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17420 entries, 0 to 17419\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   unique_id  17420 non-null  object        \n",
      " 1   ds         17420 non-null  datetime64[ns]\n",
      " 2   y          17420 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 408.4+ KB\n",
      "None\n",
      "  unique_id                  ds          y\n",
      "0        OT 2016-07-01 00:00:00  30.531000\n",
      "1        OT 2016-07-01 01:00:00  27.787001\n",
      "2        OT 2016-07-01 02:00:00  27.787001\n",
      "3        OT 2016-07-01 03:00:00  25.044001\n",
      "4        OT 2016-07-01 04:00:00  21.948000\n",
      "Most common time difference: 0 days 01:00:00\n",
      "\n",
      "Loading dataset: ETTm2\n",
      "File path: /Users/moji/PyTSF-MfG/data/ETTm2.csv\n",
      "Date parsing complete for ETTm2\n",
      "Dataset shape for ETTm2: (69680, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69680 entries, 0 to 69679\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   unique_id  69680 non-null  object        \n",
      " 1   ds         69680 non-null  datetime64[ns]\n",
      " 2   y          69680 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 1.6+ MB\n",
      "None\n",
      "  unique_id                  ds          y\n",
      "0        OT 2016-07-01 00:00:00  38.661999\n",
      "1        OT 2016-07-01 00:15:00  38.223000\n",
      "2        OT 2016-07-01 00:30:00  37.344002\n",
      "3        OT 2016-07-01 00:45:00  37.124001\n",
      "4        OT 2016-07-01 01:00:00  37.124001\n",
      "Most common time difference: 0 days 00:15:00\n",
      "\n",
      "Loading dataset: ai4i2020\n",
      "File path: /Users/moji/PyTSF-MfG/data/ai4i2020.csv\n",
      "Dataset shape for ai4i2020: (10000, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   unique_id  10000 non-null  object        \n",
      " 1   ds         10000 non-null  datetime64[ns]\n",
      " 2   y          10000 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 234.5+ KB\n",
      "None\n",
      "             unique_id                  ds      y\n",
      "0  Process_temperature 1970-01-01 00:00:00  308.6\n",
      "1  Process_temperature 1970-01-01 00:01:00  308.7\n",
      "2  Process_temperature 1970-01-01 00:02:00  308.5\n",
      "3  Process_temperature 1970-01-01 00:03:00  308.6\n",
      "4  Process_temperature 1970-01-01 00:04:00  308.7\n",
      "Most common time difference: 0 days 00:01:00\n",
      "\n",
      "Loading dataset: Steel_industry_Usage_kWh\n",
      "File path: /Users/moji/PyTSF-MfG/data/Steel_industry.csv\n",
      "Date parsing complete for Steel_industry_Usage_kWh\n",
      "Dataset shape for Steel_industry_Usage_kWh: (35041, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35041 entries, 0 to 35040\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   unique_id  35041 non-null  object        \n",
      " 1   ds         35041 non-null  datetime64[ns]\n",
      " 2   y          35041 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 821.4+ KB\n",
      "None\n",
      "   unique_id                  ds     y\n",
      "0  Usage_kWh 2018-01-01 00:15:00  3.17\n",
      "1  Usage_kWh 2018-01-01 00:30:00  4.00\n",
      "2  Usage_kWh 2018-01-01 00:45:00  3.24\n",
      "3  Usage_kWh 2018-01-01 01:00:00  3.31\n",
      "4  Usage_kWh 2018-01-01 01:15:00  3.82\n",
      "Most common time difference: 0 days 00:15:00\n",
      "\n",
      "Loading dataset: BrentOilPrices\n",
      "File path: /Users/moji/PyTSF-MfG/data/BrentOilPrices.csv\n",
      "Date parsing complete for BrentOilPrices\n",
      "Dataset shape for BrentOilPrices: (12963, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12963 entries, 0 to 12962\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   unique_id  12963 non-null  object        \n",
      " 1   ds         12963 non-null  datetime64[ns]\n",
      " 2   y          12963 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 303.9+ KB\n",
      "None\n",
      "  unique_id         ds          y\n",
      "0     Price 1987-05-20  18.630000\n",
      "1     Price 1987-05-21  18.450000\n",
      "2     Price 1987-05-22  18.550000\n",
      "3     Price 1987-05-23  18.566667\n",
      "4     Price 1987-05-24  18.583333\n",
      "Most common time difference: 1 days 00:00:00\n",
      "\n",
      "Loading dataset: ECL\n",
      "File path: /Users/moji/PyTSF-MfG/data/ECL.csv\n",
      "Date parsing complete for ECL\n",
      "Dataset shape for ECL: (26304, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26304 entries, 0 to 26303\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   unique_id  26304 non-null  object        \n",
      " 1   ds         26304 non-null  datetime64[ns]\n",
      " 2   y          26304 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 616.6+ KB\n",
      "None\n",
      "  unique_id                  ds       y\n",
      "0    MT_320 2012-01-01 00:00:00  2162.0\n",
      "1    MT_320 2012-01-01 01:00:00  2835.0\n",
      "2    MT_320 2012-01-01 02:00:00  2764.0\n",
      "3    MT_320 2012-01-01 03:00:00  2735.0\n",
      "4    MT_320 2012-01-01 04:00:00  2721.0\n",
      "Most common time difference: 0 days 01:00:00\n",
      "\n",
      "Loading dataset: Monroe Water Treatment Plant\n",
      "File path: /Users/moji/PyTSF-MfG/data/MWTP_Elec_Daily.csv\n",
      "Warning: Could not infer consistent date format for column 'date'. Falling back to flexible parsing, which may be slow and inconsistent.\n",
      "Date parsing complete for Monroe Water Treatment Plant\n",
      "Dataset shape for Monroe Water Treatment Plant: (5357, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5357 entries, 0 to 5356\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   unique_id  5357 non-null   object        \n",
      " 1   ds         5357 non-null   datetime64[ns]\n",
      " 2   y          5357 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 125.7+ KB\n",
      "None\n",
      "   unique_id         ds        y\n",
      "0  total_kwh 2010-01-01  13014.0\n",
      "1  total_kwh 2010-01-02  14058.0\n",
      "2  total_kwh 2010-01-03  14560.8\n",
      "3  total_kwh 2010-01-04  14814.0\n",
      "4  total_kwh 2010-01-05  15052.8\n",
      "Most common time difference: 1 days 00:00:00\n",
      "\n",
      "Loading dataset: Appliances Energy\n",
      "File path: /Users/moji/PyTSF-MfG/data/energydata_complete.csv\n",
      "Date parsing complete for Appliances Energy\n",
      "Dataset shape for Appliances Energy: (19735, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19735 entries, 0 to 19734\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   unique_id  19735 non-null  object        \n",
      " 1   ds         19735 non-null  datetime64[ns]\n",
      " 2   y          19735 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 462.7+ KB\n",
      "None\n",
      "     unique_id                  ds      y\n",
      "0  Press_mm_hg 2016-01-11 17:00:00  733.5\n",
      "1  Press_mm_hg 2016-01-11 17:10:00  733.6\n",
      "2  Press_mm_hg 2016-01-11 17:20:00  733.7\n",
      "3  Press_mm_hg 2016-01-11 17:30:00  733.8\n",
      "4  Press_mm_hg 2016-01-11 17:40:00  733.9\n",
      "Most common time difference: 0 days 00:10:00\n",
      "\n",
      "Loading dataset: Seoul Bike Demand\n",
      "File path: /Users/moji/PyTSF-MfG/data/SeoulBikeData_processed.csv\n",
      "Date parsing complete for Seoul Bike Demand\n",
      "Dataset shape for Seoul Bike Demand: (8760, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8760 entries, 0 to 8759\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   unique_id  8760 non-null   object        \n",
      " 1   ds         8760 non-null   datetime64[ns]\n",
      " 2   y          8760 non-null   int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(1)\n",
      "memory usage: 205.4+ KB\n",
      "None\n",
      "           unique_id                  ds    y\n",
      "0  Rented_Bike_Count 2017-12-01 00:00:00  254\n",
      "1  Rented_Bike_Count 2017-12-01 01:00:00  204\n",
      "2  Rented_Bike_Count 2017-12-01 02:00:00  173\n",
      "3  Rented_Bike_Count 2017-12-01 03:00:00  107\n",
      "4  Rented_Bike_Count 2017-12-01 04:00:00   78\n",
      "Most common time difference: 0 days 01:00:00\n",
      "\n",
      "Loading dataset: Gas sensor dynamic gas mixtures\n",
      "File path: /Users/moji/PyTSF-MfG/data/gas_sensors_dynamic_mixtures.csv\n",
      "Date parsing complete for Gas sensor dynamic gas mixtures\n",
      "Dataset shape for Gas sensor dynamic gas mixtures: (41791, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41791 entries, 0 to 41790\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   unique_id  41791 non-null  object        \n",
      " 1   ds         41791 non-null  datetime64[ns]\n",
      " 2   y          41791 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 979.6+ KB\n",
      "None\n",
      "   unique_id                  ds        y\n",
      "0  sensor_16 1970-01-01 00:00:00  3128.49\n",
      "1  sensor_16 1970-01-01 00:00:01  3131.01\n",
      "2  sensor_16 1970-01-01 00:00:02  3128.21\n",
      "3  sensor_16 1970-01-01 00:00:03  3133.82\n",
      "4  sensor_16 1970-01-01 00:00:04  3135.50\n",
      "Most common time difference: 0 days 00:00:01\n",
      "\n",
      "Loading dataset: Gas sensor temperature modulation\n",
      "File path: /Users/moji/PyTSF-MfG/data/gas_sensors_temperature.csv\n",
      "Date parsing complete for Gas sensor temperature modulation\n",
      "Dataset shape for Gas sensor temperature modulation: (36602, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36602 entries, 0 to 36601\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   unique_id  36602 non-null  object        \n",
      " 1   ds         36602 non-null  datetime64[ns]\n",
      " 2   y          36602 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 858.0+ KB\n",
      "None\n",
      "     unique_id                  ds          y\n",
      "0  Temperature 2016-09-30 00:00:00  26.592366\n",
      "1  Temperature 2016-09-30 00:00:30  26.620000\n",
      "2  Temperature 2016-09-30 00:01:00  26.602198\n",
      "3  Temperature 2016-09-30 00:01:30  26.598585\n",
      "4  Temperature 2016-09-30 00:02:00  26.586248\n",
      "Most common time difference: 0 days 00:00:30\n",
      "\n",
      "Loading dataset: ISO-NY\n",
      "File path: /Users/moji/PyTSF-MfG/data/ISO-NY_Central.csv\n",
      "Date parsing complete for ISO-NY\n",
      "Dataset shape for ISO-NY: (58324, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58324 entries, 0 to 58323\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   unique_id  58324 non-null  object        \n",
      " 1   ds         58324 non-null  datetime64[ns]\n",
      " 2   y          58324 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 1.3+ MB\n",
      "None\n",
      "  unique_id                  ds          y\n",
      "0      Load 2023-01-01 00:00:00  1452.1995\n",
      "1      Load 2023-01-01 00:15:00  1446.8088\n",
      "2      Load 2023-01-01 00:30:00  1393.8522\n",
      "3      Load 2023-01-01 00:45:00  1434.0576\n",
      "4      Load 2023-01-01 01:00:00  1416.6898\n",
      "Most common time difference: 0 days 00:15:00\n",
      "the number of datasets: 13\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T00:43:29.766327Z",
     "start_time": "2024-10-01T00:43:29.756170Z"
    }
   },
   "cell_type": "code",
   "source": "datasets['Steel_industry_Usage_kWh']",
   "id": "8b4ba9c861bf7ddd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       unique_id                  ds     y\n",
       "0      Usage_kWh 2018-01-01 00:15:00  3.17\n",
       "1      Usage_kWh 2018-01-01 00:30:00  4.00\n",
       "2      Usage_kWh 2018-01-01 00:45:00  3.24\n",
       "3      Usage_kWh 2018-01-01 01:00:00  3.31\n",
       "4      Usage_kWh 2018-01-01 01:15:00  3.82\n",
       "...          ...                 ...   ...\n",
       "35036  Usage_kWh 2018-12-31 23:15:00  3.74\n",
       "35037  Usage_kWh 2018-12-31 23:30:00  3.78\n",
       "35038  Usage_kWh 2018-12-31 23:45:00  3.78\n",
       "35039  Usage_kWh 2018-12-31 00:00:00  3.67\n",
       "35040  Usage_kWh 2018-12-31 20:00:00  4.15\n",
       "\n",
       "[35041 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Usage_kWh</td>\n",
       "      <td>2018-01-01 00:15:00</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Usage_kWh</td>\n",
       "      <td>2018-01-01 00:30:00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Usage_kWh</td>\n",
       "      <td>2018-01-01 00:45:00</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Usage_kWh</td>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Usage_kWh</td>\n",
       "      <td>2018-01-01 01:15:00</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>Usage_kWh</td>\n",
       "      <td>2018-12-31 23:15:00</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>Usage_kWh</td>\n",
       "      <td>2018-12-31 23:30:00</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>Usage_kWh</td>\n",
       "      <td>2018-12-31 23:45:00</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>Usage_kWh</td>\n",
       "      <td>2018-12-31 00:00:00</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35040</th>\n",
       "      <td>Usage_kWh</td>\n",
       "      <td>2018-12-31 20:00:00</td>\n",
       "      <td>4.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35041 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T00:45:57.629589Z",
     "start_time": "2024-10-01T00:45:57.620093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = datasets['Steel_industry_Usage_kWh']\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset info:\")\n",
    "print(df.info())"
   ],
   "id": "ae3fb51fb2b8d7f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35041 entries, 0 to 35040\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   unique_id  35041 non-null  object        \n",
      " 1   ds         35041 non-null  datetime64[ns]\n",
      " 2   y          35041 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 821.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T00:46:45.919379Z",
     "start_time": "2024-10-01T00:46:45.907559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nDataset head:\")\n",
    "print(df.head())\n",
    "# Check for duplicate timestamps\n",
    "duplicates = df[df.duplicated(subset=['ds'], keep=False)]\n",
    "print(f\"\\nNumber of rows with duplicate timestamps: {len(duplicates)}\")\n"
   ],
   "id": "560e730a9d66e621",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset head:\n",
      "   unique_id                  ds     y\n",
      "0  Usage_kWh 2018-01-01 00:15:00  3.17\n",
      "1  Usage_kWh 2018-01-01 00:30:00  4.00\n",
      "2  Usage_kWh 2018-01-01 00:45:00  3.24\n",
      "3  Usage_kWh 2018-01-01 01:00:00  3.31\n",
      "4  Usage_kWh 2018-01-01 01:15:00  3.82\n",
      "\n",
      "Number of rows with duplicate timestamps: 2\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T00:48:20.448046Z",
     "start_time": "2024-10-01T00:48:20.379680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if len(duplicates) > 0:\n",
    "    print(\"\\nSample of duplicate timestamps:\")\n",
    "    print(duplicates.head(10))  # Show first 10 duplicates\n",
    "\n",
    "    # Option 1: Keep the first occurrence of each timestamp\n",
    "    df_deduped = df.drop_duplicates(subset=['ds'], keep='first')\n",
    "\n",
    "    # Option 2: Aggregate data for duplicate timestamps (e.g., taking the mean)\n",
    "    # df_deduped = df.groupby(['unique_id', 'ds'])['y'].mean().reset_index()\n",
    "\n",
    "    print(f\"\\nShape of dataset after deduplication: {df_deduped.shape}\")\n",
    "\n",
    "    # Check if deduplication resolved the issue\n",
    "    if df_deduped['ds'].is_unique:\n",
    "        print(\"Deduplication successful. Timestamps are now unique.\")\n",
    "    else:\n",
    "        print(\"Deduplication did not resolve all duplicates. Further investigation needed.\")\n",
    "\n",
    "    # Save the deduplicated dataset\n",
    "    output_path = '/Users/moji/PyTSF-MfG/data/deduplicated_dataset.csv'  # Replace with your desired output path\n",
    "    df_deduped.to_csv(output_path)\n",
    "    print(f\"\\nDeduplicated dataset saved as: {output_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"No duplicate timestamps found. The issue may be elsewhere.\")"
   ],
   "id": "c60447b5d6fb02d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of duplicate timestamps:\n",
      "       unique_id                  ds     y\n",
      "35023  Usage_kWh 2018-12-31 20:00:00  4.14\n",
      "35040  Usage_kWh 2018-12-31 20:00:00  4.15\n",
      "\n",
      "Shape of dataset after deduplication: (35040, 3)\n",
      "Deduplication successful. Timestamps are now unique.\n",
      "\n",
      "Deduplicated dataset saved as: /Users/moji/PyTSF-MfG/data/deduplicated_dataset.csv\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T00:49:07.843209Z",
     "start_time": "2024-10-01T00:49:07.829036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "# Additional checks\n",
    "print(\"\\nUnique values in 'unique_id' column:\")\n",
    "print(df['unique_id'].unique())\n",
    "\n",
    "print(\"\\nDate range:\")\n",
    "print(f\"Start: {df['ds'].min()}\")\n",
    "print(f\"End: {df['ds'].max()}\")\n",
    "\n",
    "# Check for any inconsistencies in the time intervals\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "time_diff = df['ds'].diff()\n",
    "inconsistent_intervals = time_diff[time_diff != pd.Timedelta(minutes=15)]\n",
    "if not inconsistent_intervals.empty:\n",
    "    print(\"\\nInconsistent time intervals found:\")\n",
    "    print(inconsistent_intervals.head())\n",
    "else:\n",
    "    print(\"\\nAll time intervals are consistent (15 minutes).\")"
   ],
   "id": "e4846946caf66c59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in 'unique_id' column:\n",
      "['Usage_kWh']\n",
      "\n",
      "Date range:\n",
      "Start: 2018-01-01 00:00:00\n",
      "End: 2018-12-31 23:45:00\n",
      "\n",
      "Inconsistent time intervals found:\n",
      "0                   NaT\n",
      "95    -1 days +00:15:00\n",
      "96      1 days 00:15:00\n",
      "191   -1 days +00:15:00\n",
      "192     1 days 00:15:00\n",
      "Name: ds, dtype: timedelta64[ns]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_path = '/Users/moji/PyTSF-MfG/data'\n",
    "datasets = load_datasets_statforecast_uni(data_path)"
   ],
   "id": "c12cfcbb08468ffe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/moji/PyTSF-MfG/data/BrentOilPrices.csv')\n",
    "# Convert 'Date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='mixed')\n",
    "# Set 'Date' as the index\n",
    "df.set_index('Date', inplace=True)\n",
    "# Sort the index to ensure chronological order\n",
    "df.sort_index(inplace=True)\n",
    "# Create a complete date range including weekends\n",
    "date_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='D')\n",
    "# Reindex the dataframe with the complete date range\n",
    "df_reindexed = df.reindex(date_range)\n",
    "# Check for missing values after reindexing\n",
    "print(\"Missing values after reindexing (including weekends):\")\n",
    "print(df_reindexed.isnull().sum())\n",
    "# Interpolate missing values\n",
    "df_interpolated = df_reindexed.interpolate(method='time')\n",
    "# Check for missing values after interpolation\n",
    "print(\"\\nMissing values after interpolation:\")\n",
    "print(df_interpolated.isnull().sum())\n",
    "# Fill any remaining NaN values at the beginning or end with the nearest valid value\n",
    "df_interpolated = df_interpolated.fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "# Save the new dataset without missing values\n",
    "output_path = '/Users/moji/PyTSF-MfG/data/BrentOilPrices_Interpolated.csv'\n",
    "df_interpolated.to_csv(output_path)\n",
    "print(f\"\\nNew dataset saved as '{output_path}'\")\n",
    "\n",
    "# Display the first few rows of the interpolated dataset\n",
    "print(\"\\nFirst few rows of the interpolated dataset:\")\n",
    "print(df_interpolated.head())\n",
    "\n",
    "# Display basic statistics of the interpolated dataset\n",
    "print(\"\\nBasic statistics of the interpolated dataset:\")\n",
    "print(df_interpolated.describe())"
   ],
   "id": "8bce8c25950025bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/moji/PyTSF-MfG/data/ISO-NY_Central.csv')\n",
    "print(df.shape)\n",
    "# Convert 'Time_Stamp' column to datetime\n",
    "df['Time_Stamp'] = pd.to_datetime(df['Time_Stamp'])\n",
    "\n",
    "# Set 'Time_Stamp' as the index\n",
    "df.set_index('Time_Stamp', inplace=True)\n",
    "\n",
    "# Sort the index to ensure chronological order\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# Create a complete time range with 15-minute intervals\n",
    "time_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='15min')\n",
    "\n",
    "# Reindex the dataframe with the complete time range\n",
    "df_reindexed = df.reindex(time_range)\n",
    "print(df_reindexed.shape)\n",
    "# Check for missing values after reindexing\n",
    "print(\"Missing values after reindexing:\")\n",
    "print(df_reindexed.isnull().sum())\n",
    "# Interpolate missing values\n",
    "df_interpolated = df_reindexed.interpolate(method='time')\n",
    "# Check for missing values after interpolation\n",
    "print(\"\\nMissing values after interpolation:\")\n",
    "print(df_interpolated.isnull().sum())\n",
    "# Fill any remaining NaN values at the beginning or end with the nearest valid value\n",
    "df_interpolated = df_interpolated.fillna(method='bfill').fillna(method='ffill')\n",
    "# Final check for missing values\n",
    "print(\"\\nFinal check for missing values:\")\n",
    "print(df_interpolated.isnull().sum())\n",
    "\n",
    "# Save the new dataset without missing values\n",
    "output_path = '/Users/moji/PyTSF-MfG/data/LoadData_Interpolated.csv'\n",
    "df_interpolated.to_csv(output_path)\n",
    "\n",
    "print(f\"\\nNew dataset saved as '{output_path}'\")\n",
    "\n",
    "# Display the first few rows of the interpolated dataset\n",
    "print(\"\\nFirst few rows of the interpolated dataset:\")\n",
    "print(df_interpolated.head())\n",
    "\n",
    "# Display basic statistics of the interpolated dataset\n",
    "print(\"\\nBasic statistics of the interpolated dataset:\")\n",
    "print(df_interpolated.describe())\n",
    "# Check for any gaps in the time series\n",
    "time_diff = df_interpolated.index.to_series().diff()\n",
    "gaps = time_diff[time_diff > pd.Timedelta(minutes=15)]\n",
    "if not gaps.empty:\n",
    "    print(\"\\nGaps found in the time series:\")\n",
    "    print(gaps)\n",
    "else:\n",
    "    print(\"\\nNo gaps found in the time series.\")"
   ],
   "id": "c126774d1b692bb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "e4e1b64839e32b10",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
