{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-07T02:12:34.241472Z",
     "start_time": "2024-10-07T02:12:31.385338Z"
    }
   },
   "source": "from modules.utils import load_datasets_statforecast_uni",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:12:34.863475Z",
     "start_time": "2024-10-07T02:12:34.242338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = '/Users/moji/PyTSF-MfG/data'\n",
    "datasets = load_datasets_statforecast_uni(data_path)"
   ],
   "id": "d65d8480f0b433ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset: air_passengers\n",
      "File path: /Users/moji/PyTSF-MfG/data/AirPassengers.csv\n",
      "Warning: Could not infer consistent date format for column 'Month'. Falling back to flexible parsing, which may be slow and inconsistent.\n",
      "Date parsing complete for air_passengers\n",
      "Dataset shape for air_passengers: (144, 3)\n",
      "Most common time difference: 31 days 00:00:00\n",
      "\n",
      "Loading dataset: ETTh1\n",
      "File path: /Users/moji/PyTSF-MfG/data/ETTh1.csv\n",
      "Date parsing complete for ETTh1\n",
      "Dataset shape for ETTh1: (17420, 3)\n",
      "Most common time difference: 0 days 01:00:00\n",
      "\n",
      "Loading dataset: ETTm2\n",
      "File path: /Users/moji/PyTSF-MfG/data/ETTm2.csv\n",
      "Date parsing complete for ETTm2\n",
      "Dataset shape for ETTm2: (69680, 3)\n",
      "Most common time difference: 0 days 00:15:00\n",
      "\n",
      "Loading dataset: ai4i2020\n",
      "File path: /Users/moji/PyTSF-MfG/data/ai4i2020.csv\n",
      "Dataset shape for ai4i2020: (10000, 3)\n",
      "Most common time difference: 0 days 00:01:00\n",
      "\n",
      "Loading dataset: Steel_industry_Usage_kWh\n",
      "File path: /Users/moji/PyTSF-MfG/data/Steel_industry.csv\n",
      "Dataset shape for Steel_industry_Usage_kWh: (35040, 3)\n",
      "Most common time difference: 0 days 00:15:00\n",
      "\n",
      "Loading dataset: BrentOilPrices\n",
      "File path: /Users/moji/PyTSF-MfG/data/BrentOilPrices.csv\n",
      "Date parsing complete for BrentOilPrices\n",
      "Dataset shape for BrentOilPrices: (12963, 3)\n",
      "Most common time difference: 1 days 00:00:00\n",
      "\n",
      "Loading dataset: ECL\n",
      "File path: /Users/moji/PyTSF-MfG/data/ECL.csv\n",
      "Date parsing complete for ECL\n",
      "Dataset shape for ECL: (26304, 3)\n",
      "Most common time difference: 0 days 01:00:00\n",
      "\n",
      "Loading dataset: Monroe Water Treatment Plant\n",
      "File path: /Users/moji/PyTSF-MfG/data/MWTP_Elec_Daily.csv\n",
      "Warning: Could not infer consistent date format for column 'date'. Falling back to flexible parsing, which may be slow and inconsistent.\n",
      "Date parsing complete for Monroe Water Treatment Plant\n",
      "Dataset shape for Monroe Water Treatment Plant: (5357, 3)\n",
      "Most common time difference: 1 days 00:00:00\n",
      "\n",
      "Loading dataset: Appliances Energy\n",
      "File path: /Users/moji/PyTSF-MfG/data/energydata_complete.csv\n",
      "Date parsing complete for Appliances Energy\n",
      "Dataset shape for Appliances Energy: (19735, 3)\n",
      "Most common time difference: 0 days 00:10:00\n",
      "\n",
      "Loading dataset: Seoul Bike Demand\n",
      "File path: /Users/moji/PyTSF-MfG/data/SeoulBikeData_processed.csv\n",
      "Date parsing complete for Seoul Bike Demand\n",
      "Dataset shape for Seoul Bike Demand: (8760, 3)\n",
      "Most common time difference: 0 days 01:00:00\n",
      "\n",
      "Loading dataset: Gas sensor dynamic gas mixtures\n",
      "File path: /Users/moji/PyTSF-MfG/data/gas_sensors_dynamic_mixtures.csv\n",
      "Date parsing complete for Gas sensor dynamic gas mixtures\n",
      "Dataset shape for Gas sensor dynamic gas mixtures: (41791, 3)\n",
      "Most common time difference: 0 days 00:00:01\n",
      "\n",
      "Loading dataset: Gas sensor temperature modulation\n",
      "File path: /Users/moji/PyTSF-MfG/data/gas_sensors_temperature.csv\n",
      "Date parsing complete for Gas sensor temperature modulation\n",
      "Dataset shape for Gas sensor temperature modulation: (36602, 3)\n",
      "Most common time difference: 0 days 00:00:30\n",
      "\n",
      "Loading dataset: ISO-NY\n",
      "File path: /Users/moji/PyTSF-MfG/data/ISO-NY_Central.csv\n",
      "Date parsing complete for ISO-NY\n",
      "Dataset shape for ISO-NY: (58324, 3)\n",
      "Most common time difference: 0 days 00:15:00\n",
      "the number of datasets: 13\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:12:34.891177Z",
     "start_time": "2024-10-07T02:12:34.864148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "file_path = '/Users/moji/PyTSF-MfG/data/Steel_industry2.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ],
   "id": "8b4ba9c861bf7ddd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              Date_Time  Usage_kWh  Lagging_Current_Reactive.Power_kVarh  \\\n",
       "0      01-01-2018 00:15       3.17                                  2.95   \n",
       "1      01-01-2018 00:30       4.00                                  4.46   \n",
       "2      01-01-2018 00:45       3.24                                  3.28   \n",
       "3      01-01-2018 01:00       3.31                                  3.56   \n",
       "4      01-01-2018 01:15       3.82                                  4.50   \n",
       "...                 ...        ...                                   ...   \n",
       "35036  31-12-2018 23:15       3.74                                  3.74   \n",
       "35037  31-12-2018 23:30       3.78                                  3.17   \n",
       "35038  31-12-2018 23:45       3.78                                  3.06   \n",
       "35039  31-12-2018 00:00       3.67                                  3.02   \n",
       "35040  31-12-2018 20:00       4.15                                  0.00   \n",
       "\n",
       "       Leading_Current_Reactive_Power_kVarh  CO2(tCO2)  \\\n",
       "0                                      0.00        0.0   \n",
       "1                                      0.00        0.0   \n",
       "2                                      0.00        0.0   \n",
       "3                                      0.00        0.0   \n",
       "4                                      0.00        0.0   \n",
       "...                                     ...        ...   \n",
       "35036                                  0.00        0.0   \n",
       "35037                                  0.07        0.0   \n",
       "35038                                  0.11        0.0   \n",
       "35039                                  0.07        0.0   \n",
       "35040                                 20.10        0.0   \n",
       "\n",
       "       Lagging_Current_Power_Factor  Leading_Current_Power_Factor    NSM  \\\n",
       "0                             73.21                        100.00    900   \n",
       "1                             66.77                        100.00   1800   \n",
       "2                             70.28                        100.00   2700   \n",
       "3                             68.09                        100.00   3600   \n",
       "4                             64.72                        100.00   4500   \n",
       "...                             ...                           ...    ...   \n",
       "35036                         70.71                        100.00  83700   \n",
       "35037                         76.62                         99.98  84600   \n",
       "35038                         77.72                         99.96  85500   \n",
       "35039                         77.22                         99.98      0   \n",
       "35040                        100.00                         20.19  72000   \n",
       "\n",
       "      WeekStatus Day_Of_Week   Load_Type  \n",
       "0        Weekday      Monday  Light_Load  \n",
       "1        Weekday      Monday  Light_Load  \n",
       "2        Weekday      Monday  Light_Load  \n",
       "3        Weekday      Monday  Light_Load  \n",
       "4        Weekday      Monday  Light_Load  \n",
       "...          ...         ...         ...  \n",
       "35036    Weekday      Monday  Light_Load  \n",
       "35037    Weekday      Monday  Light_Load  \n",
       "35038    Weekday      Monday  Light_Load  \n",
       "35039    Weekday      Monday  Light_Load  \n",
       "35040    Weekday      Monday  Light_Load  \n",
       "\n",
       "[35041 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Usage_kWh</th>\n",
       "      <th>Lagging_Current_Reactive.Power_kVarh</th>\n",
       "      <th>Leading_Current_Reactive_Power_kVarh</th>\n",
       "      <th>CO2(tCO2)</th>\n",
       "      <th>Lagging_Current_Power_Factor</th>\n",
       "      <th>Leading_Current_Power_Factor</th>\n",
       "      <th>NSM</th>\n",
       "      <th>WeekStatus</th>\n",
       "      <th>Day_Of_Week</th>\n",
       "      <th>Load_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2018 00:15</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.21</td>\n",
       "      <td>100.00</td>\n",
       "      <td>900</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-01-2018 00:30</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.77</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1800</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-01-2018 00:45</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.28</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2700</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-01-2018 01:00</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.09</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3600</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-01-2018 01:15</td>\n",
       "      <td>3.82</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.72</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4500</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>31-12-2018 23:15</td>\n",
       "      <td>3.74</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.71</td>\n",
       "      <td>100.00</td>\n",
       "      <td>83700</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>31-12-2018 23:30</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.62</td>\n",
       "      <td>99.98</td>\n",
       "      <td>84600</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>31-12-2018 23:45</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.72</td>\n",
       "      <td>99.96</td>\n",
       "      <td>85500</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35039</th>\n",
       "      <td>31-12-2018 00:00</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.22</td>\n",
       "      <td>99.98</td>\n",
       "      <td>0</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35040</th>\n",
       "      <td>31-12-2018 20:00</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>20.19</td>\n",
       "      <td>72000</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35041 rows Ã— 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:12:34.898567Z",
     "start_time": "2024-10-07T02:12:34.891718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset info:\")\n",
    "print(df.info())"
   ],
   "id": "ae3fb51fb2b8d7f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35041 entries, 0 to 35040\n",
      "Data columns (total 11 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   Date_Time                             35041 non-null  object \n",
      " 1   Usage_kWh                             35041 non-null  float64\n",
      " 2   Lagging_Current_Reactive.Power_kVarh  35041 non-null  float64\n",
      " 3   Leading_Current_Reactive_Power_kVarh  35041 non-null  float64\n",
      " 4   CO2(tCO2)                             35041 non-null  float64\n",
      " 5   Lagging_Current_Power_Factor          35041 non-null  float64\n",
      " 6   Leading_Current_Power_Factor          35041 non-null  float64\n",
      " 7   NSM                                   35041 non-null  int64  \n",
      " 8   WeekStatus                            35041 non-null  object \n",
      " 9   Day_Of_Week                           35041 non-null  object \n",
      " 10  Load_Type                             35041 non-null  object \n",
      "dtypes: float64(6), int64(1), object(4)\n",
      "memory usage: 2.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:12:34.904297Z",
     "start_time": "2024-10-07T02:12:34.899685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nDataset head:\")\n",
    "print(df.head())\n",
    "# Check for duplicate timestamps\n",
    "duplicates = df[df.duplicated(subset=['Date_Time'], keep=False)]\n",
    "print(f\"\\nNumber of rows with duplicate timestamps: {len(duplicates)}\")\n"
   ],
   "id": "560e730a9d66e621",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset head:\n",
      "          Date_Time  Usage_kWh  Lagging_Current_Reactive.Power_kVarh  \\\n",
      "0  01-01-2018 00:15       3.17                                  2.95   \n",
      "1  01-01-2018 00:30       4.00                                  4.46   \n",
      "2  01-01-2018 00:45       3.24                                  3.28   \n",
      "3  01-01-2018 01:00       3.31                                  3.56   \n",
      "4  01-01-2018 01:15       3.82                                  4.50   \n",
      "\n",
      "   Leading_Current_Reactive_Power_kVarh  CO2(tCO2)  \\\n",
      "0                                   0.0        0.0   \n",
      "1                                   0.0        0.0   \n",
      "2                                   0.0        0.0   \n",
      "3                                   0.0        0.0   \n",
      "4                                   0.0        0.0   \n",
      "\n",
      "   Lagging_Current_Power_Factor  Leading_Current_Power_Factor   NSM  \\\n",
      "0                         73.21                         100.0   900   \n",
      "1                         66.77                         100.0  1800   \n",
      "2                         70.28                         100.0  2700   \n",
      "3                         68.09                         100.0  3600   \n",
      "4                         64.72                         100.0  4500   \n",
      "\n",
      "  WeekStatus Day_Of_Week   Load_Type  \n",
      "0    Weekday      Monday  Light_Load  \n",
      "1    Weekday      Monday  Light_Load  \n",
      "2    Weekday      Monday  Light_Load  \n",
      "3    Weekday      Monday  Light_Load  \n",
      "4    Weekday      Monday  Light_Load  \n",
      "\n",
      "Number of rows with duplicate timestamps: 2\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:12:34.911010Z",
     "start_time": "2024-10-07T02:12:34.904803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if len(duplicates) > 0:\n",
    "    print(\"\\nSample of duplicate timestamps:\")\n",
    "    print(duplicates.head(10))  # Show first 10 duplicates\n",
    "\n",
    "    # Option 1: Keep the first occurrence of each timestamp\n",
    "    df_deduped = df.drop_duplicates(subset=['Date_Time'], keep='first')\n",
    "\n",
    "    # Option 2: Aggregate data for duplicate timestamps (e.g., taking the mean)\n",
    "    # df_deduped = df.groupby(['unique_id', 'ds'])['y'].mean().reset_index()\n",
    "\n",
    "    print(f\"\\nShape of dataset after deduplication: {df_deduped.shape}\")\n",
    "\n",
    "    # Check if deduplication resolved the issue\n",
    "    if df_deduped['Date_Time'].is_unique:\n",
    "        print(\"Deduplication successful. Timestamps are now unique.\")\n",
    "    else:\n",
    "        print(\"Deduplication did not resolve all duplicates. Further investigation needed.\")\n",
    "\n",
    "    # # Save the deduplicated dataset\n",
    "    # output_path = '/Users/moji/PyTSF-MfG/data/deduplicated_dataset.csv'  # Replace with your desired output path\n",
    "    # df_deduped.to_csv(output_path, index_label='id')\n",
    "    # print(f\"\\nDeduplicated dataset saved as: {output_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"No duplicate timestamps found. The issue may be elsewhere.\")"
   ],
   "id": "c60447b5d6fb02d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of duplicate timestamps:\n",
      "              Date_Time  Usage_kWh  Lagging_Current_Reactive.Power_kVarh  \\\n",
      "35023  31-12-2018 20:00       4.14                                   0.0   \n",
      "35040  31-12-2018 20:00       4.15                                   0.0   \n",
      "\n",
      "       Leading_Current_Reactive_Power_kVarh  CO2(tCO2)  \\\n",
      "35023                                 20.09        0.0   \n",
      "35040                                 20.10        0.0   \n",
      "\n",
      "       Lagging_Current_Power_Factor  Leading_Current_Power_Factor    NSM  \\\n",
      "35023                         100.0                         20.18  72000   \n",
      "35040                         100.0                         20.19  72000   \n",
      "\n",
      "      WeekStatus Day_Of_Week   Load_Type  \n",
      "35023    Weekday      Monday  Light_Load  \n",
      "35040    Weekday      Monday  Light_Load  \n",
      "\n",
      "Shape of dataset after deduplication: (35040, 11)\n",
      "Deduplication successful. Timestamps are now unique.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:12:35.086696Z",
     "start_time": "2024-10-07T02:12:34.911585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "# Make an explicit copy to ensure we're working with a new DataFrame\n",
    "df_deduped = df_deduped.copy()\n",
    "\n",
    "print(\"\\nDate range:\")\n",
    "print(f\"Start: {df_deduped['Date_Time'].min()}\")\n",
    "print(f\"End: {df_deduped['Date_Time'].max()}\")\n",
    "\n",
    "# Convert 'Date_Time' to datetime using .loc\n",
    "df_deduped.loc[:, 'Date_Time'] = pd.to_datetime(df_deduped['Date_Time'], format='%d-%m-%Y %H:%M')\n",
    "\n",
    "# Check for any inconsistencies in the time intervals\n",
    "time_diff = df_deduped['Date_Time'].diff()\n",
    "inconsistent_intervals = time_diff[time_diff != pd.Timedelta(minutes=15)]\n",
    "if not inconsistent_intervals.empty:\n",
    "    print(\"\\nInconsistent time intervals found:\")\n",
    "    print(inconsistent_intervals.head())\n",
    "else:\n",
    "    print(\"\\nAll time intervals are consistent (15 minutes).\")"
   ],
   "id": "e4846946caf66c59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Date range:\n",
      "Start: 01-01-2018 00:00\n",
      "End: 31-12-2018 23:45\n",
      "\n",
      "Inconsistent time intervals found:\n",
      "0                   NaT\n",
      "95    -1 days +00:15:00\n",
      "96      1 days 00:15:00\n",
      "191   -1 days +00:15:00\n",
      "192     1 days 00:15:00\n",
      "Name: Date_Time, dtype: timedelta64[ns]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:12:37.152047Z",
     "start_time": "2024-10-07T02:12:37.006102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "df = df_deduped.copy()\n",
    "# Convert 'Date' column to datetime\n",
    "df['Date_Time'] = pd.to_datetime(df['Date_Time'], format='%d-%m-%Y %H:%M')\n",
    "# Set 'Date' as the index\n",
    "df.set_index('Date_Time', inplace=True)\n",
    "# Sort the index to ensure chronological order\n",
    "df.sort_index(inplace=True)\n",
    "# Create a complete date range including weekends\n",
    "date_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='15min')\n",
    "# Reindex the dataframe with the complete date range\n",
    "df_reindexed = df.reindex(date_range)\n",
    "# Check for missing values after reindexing\n",
    "print(\"Missing values after reindexing (including weekends):\")\n",
    "print(df_reindexed.isnull().sum())\n",
    "# Interpolate missing values\n",
    "df_interpolated = df_reindexed.interpolate(method='time')\n",
    "# Check for missing values after interpolation\n",
    "print(\"\\nMissing values after interpolation:\")\n",
    "print(df_interpolated.isnull().sum())\n",
    "# Fill any remaining NaN values at the beginning or end with the nearest valid value\n",
    "df_interpolated = df_interpolated.fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "# Save the new dataset without missing values\n",
    "output_path = '/Users/moji/PyTSF-MfG/data/steel_Interpolated.csv'\n",
    "df_interpolated.to_csv(output_path)\n",
    "print(f\"\\nNew dataset saved as '{output_path}'\")\n",
    "\n",
    "# Display the first few rows of the interpolated dataset\n",
    "print(\"\\nFirst few rows of the interpolated dataset:\")\n",
    "print(df_interpolated.head())\n",
    "\n",
    "# Display basic statistics of the interpolated dataset\n",
    "print(\"\\nBasic statistics of the interpolated dataset:\")\n",
    "print(df_interpolated.describe())"
   ],
   "id": "f029851624477495",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after reindexing (including weekends):\n",
      "Usage_kWh                               0\n",
      "Lagging_Current_Reactive.Power_kVarh    0\n",
      "Leading_Current_Reactive_Power_kVarh    0\n",
      "CO2(tCO2)                               0\n",
      "Lagging_Current_Power_Factor            0\n",
      "Leading_Current_Power_Factor            0\n",
      "NSM                                     0\n",
      "WeekStatus                              0\n",
      "Day_Of_Week                             0\n",
      "Load_Type                               0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after interpolation:\n",
      "Usage_kWh                               0\n",
      "Lagging_Current_Reactive.Power_kVarh    0\n",
      "Leading_Current_Reactive_Power_kVarh    0\n",
      "CO2(tCO2)                               0\n",
      "Lagging_Current_Power_Factor            0\n",
      "Leading_Current_Power_Factor            0\n",
      "NSM                                     0\n",
      "WeekStatus                              0\n",
      "Day_Of_Week                             0\n",
      "Load_Type                               0\n",
      "dtype: int64\n",
      "\n",
      "New dataset saved as '/Users/moji/PyTSF-MfG/data/steel_Interpolated.csv'\n",
      "\n",
      "First few rows of the interpolated dataset:\n",
      "                     Usage_kWh  Lagging_Current_Reactive.Power_kVarh  \\\n",
      "2018-01-01 00:00:00       3.42                                  3.46   \n",
      "2018-01-01 00:15:00       3.17                                  2.95   \n",
      "2018-01-01 00:30:00       4.00                                  4.46   \n",
      "2018-01-01 00:45:00       3.24                                  3.28   \n",
      "2018-01-01 01:00:00       3.31                                  3.56   \n",
      "\n",
      "                     Leading_Current_Reactive_Power_kVarh  CO2(tCO2)  \\\n",
      "2018-01-01 00:00:00                                   0.0        0.0   \n",
      "2018-01-01 00:15:00                                   0.0        0.0   \n",
      "2018-01-01 00:30:00                                   0.0        0.0   \n",
      "2018-01-01 00:45:00                                   0.0        0.0   \n",
      "2018-01-01 01:00:00                                   0.0        0.0   \n",
      "\n",
      "                     Lagging_Current_Power_Factor  \\\n",
      "2018-01-01 00:00:00                         70.30   \n",
      "2018-01-01 00:15:00                         73.21   \n",
      "2018-01-01 00:30:00                         66.77   \n",
      "2018-01-01 00:45:00                         70.28   \n",
      "2018-01-01 01:00:00                         68.09   \n",
      "\n",
      "                     Leading_Current_Power_Factor   NSM WeekStatus  \\\n",
      "2018-01-01 00:00:00                         100.0     0    Weekday   \n",
      "2018-01-01 00:15:00                         100.0   900    Weekday   \n",
      "2018-01-01 00:30:00                         100.0  1800    Weekday   \n",
      "2018-01-01 00:45:00                         100.0  2700    Weekday   \n",
      "2018-01-01 01:00:00                         100.0  3600    Weekday   \n",
      "\n",
      "                    Day_Of_Week   Load_Type  \n",
      "2018-01-01 00:00:00      Monday  Light_Load  \n",
      "2018-01-01 00:15:00      Monday  Light_Load  \n",
      "2018-01-01 00:30:00      Monday  Light_Load  \n",
      "2018-01-01 00:45:00      Monday  Light_Load  \n",
      "2018-01-01 01:00:00      Monday  Light_Load  \n",
      "\n",
      "Basic statistics of the interpolated dataset:\n",
      "          Usage_kWh  Lagging_Current_Reactive.Power_kVarh  \\\n",
      "count  35040.000000                          35040.000000   \n",
      "mean      27.386892                             13.035384   \n",
      "std       33.444380                             16.306000   \n",
      "min        0.000000                              0.000000   \n",
      "25%        3.200000                              2.300000   \n",
      "50%        4.570000                              5.000000   \n",
      "75%       51.237500                             22.640000   \n",
      "max      157.180000                             96.910000   \n",
      "\n",
      "       Leading_Current_Reactive_Power_kVarh     CO2(tCO2)  \\\n",
      "count                          35040.000000  35040.000000   \n",
      "mean                               3.870949      0.011524   \n",
      "std                                7.424463      0.016151   \n",
      "min                                0.000000      0.000000   \n",
      "25%                                0.000000      0.000000   \n",
      "50%                                0.000000      0.000000   \n",
      "75%                                2.090000      0.020000   \n",
      "max                               27.760000      0.070000   \n",
      "\n",
      "       Lagging_Current_Power_Factor  Leading_Current_Power_Factor  \\\n",
      "count                  35040.000000                  35040.000000   \n",
      "mean                      80.578056                     84.367870   \n",
      "std                       18.921322                     30.456535   \n",
      "min                        0.000000                      0.000000   \n",
      "25%                       63.320000                     99.700000   \n",
      "50%                       87.960000                    100.000000   \n",
      "75%                       99.022500                    100.000000   \n",
      "max                      100.000000                    100.000000   \n",
      "\n",
      "                NSM  \n",
      "count  35040.000000  \n",
      "mean   42750.000000  \n",
      "std    24940.534317  \n",
      "min        0.000000  \n",
      "25%    21375.000000  \n",
      "50%    42750.000000  \n",
      "75%    64125.000000  \n",
      "max    85500.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0s/whfbkk11083fmvg1wl2nrqqm0000gn/T/ipykernel_90328/642766792.py:17: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df_interpolated = df_reindexed.interpolate(method='time')\n",
      "/var/folders/0s/whfbkk11083fmvg1wl2nrqqm0000gn/T/ipykernel_90328/642766792.py:22: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_interpolated = df_interpolated.fillna(method='bfill').fillna(method='ffill')\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:16:46.835416Z",
     "start_time": "2024-10-07T02:16:46.199842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = '/Users/moji/PyTSF-MfG/data'\n",
    "datasets = load_datasets_statforecast_uni(data_path)"
   ],
   "id": "c12cfcbb08468ffe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset: air_passengers\n",
      "File path: /Users/moji/PyTSF-MfG/data/AirPassengers.csv\n",
      "Warning: Could not infer consistent date format for column 'Month'. Falling back to flexible parsing, which may be slow and inconsistent.\n",
      "Date parsing complete for air_passengers\n",
      "Dataset shape for air_passengers: (144, 3)\n",
      "Most common time difference: 31 days 00:00:00\n",
      "\n",
      "Loading dataset: ETTh1\n",
      "File path: /Users/moji/PyTSF-MfG/data/ETTh1.csv\n",
      "Date parsing complete for ETTh1\n",
      "Dataset shape for ETTh1: (17420, 3)\n",
      "Most common time difference: 0 days 01:00:00\n",
      "\n",
      "Loading dataset: ETTm2\n",
      "File path: /Users/moji/PyTSF-MfG/data/ETTm2.csv\n",
      "Date parsing complete for ETTm2\n",
      "Dataset shape for ETTm2: (69680, 3)\n",
      "Most common time difference: 0 days 00:15:00\n",
      "\n",
      "Loading dataset: ai4i2020\n",
      "File path: /Users/moji/PyTSF-MfG/data/ai4i2020.csv\n",
      "Dataset shape for ai4i2020: (10000, 3)\n",
      "Most common time difference: 0 days 00:01:00\n",
      "\n",
      "Loading dataset: Steel_industry_Usage_kWh\n",
      "File path: /Users/moji/PyTSF-MfG/data/Steel_industry.csv\n",
      "Date parsing complete for Steel_industry_Usage_kWh\n",
      "Dataset shape for Steel_industry_Usage_kWh: (35040, 3)\n",
      "Most common time difference: 0 days 00:15:00\n",
      "\n",
      "Loading dataset: BrentOilPrices\n",
      "File path: /Users/moji/PyTSF-MfG/data/BrentOilPrices.csv\n",
      "Date parsing complete for BrentOilPrices\n",
      "Dataset shape for BrentOilPrices: (12963, 3)\n",
      "Most common time difference: 1 days 00:00:00\n",
      "\n",
      "Loading dataset: ECL\n",
      "File path: /Users/moji/PyTSF-MfG/data/ECL.csv\n",
      "Date parsing complete for ECL\n",
      "Dataset shape for ECL: (26304, 3)\n",
      "Most common time difference: 0 days 01:00:00\n",
      "\n",
      "Loading dataset: Monroe Water Treatment Plant\n",
      "File path: /Users/moji/PyTSF-MfG/data/MWTP_Elec_Daily.csv\n",
      "Warning: Could not infer consistent date format for column 'date'. Falling back to flexible parsing, which may be slow and inconsistent.\n",
      "Date parsing complete for Monroe Water Treatment Plant\n",
      "Dataset shape for Monroe Water Treatment Plant: (5357, 3)\n",
      "Most common time difference: 1 days 00:00:00\n",
      "\n",
      "Loading dataset: Appliances Energy\n",
      "File path: /Users/moji/PyTSF-MfG/data/energydata_complete.csv\n",
      "Date parsing complete for Appliances Energy\n",
      "Dataset shape for Appliances Energy: (19735, 3)\n",
      "Most common time difference: 0 days 00:10:00\n",
      "\n",
      "Loading dataset: Seoul Bike Demand\n",
      "File path: /Users/moji/PyTSF-MfG/data/SeoulBikeData_processed.csv\n",
      "Date parsing complete for Seoul Bike Demand\n",
      "Dataset shape for Seoul Bike Demand: (8760, 3)\n",
      "Most common time difference: 0 days 01:00:00\n",
      "\n",
      "Loading dataset: Gas sensor dynamic gas mixtures\n",
      "File path: /Users/moji/PyTSF-MfG/data/gas_sensors_dynamic_mixtures.csv\n",
      "Date parsing complete for Gas sensor dynamic gas mixtures\n",
      "Dataset shape for Gas sensor dynamic gas mixtures: (41791, 3)\n",
      "Most common time difference: 0 days 00:00:01\n",
      "\n",
      "Loading dataset: Gas sensor temperature modulation\n",
      "File path: /Users/moji/PyTSF-MfG/data/gas_sensors_temperature.csv\n",
      "Date parsing complete for Gas sensor temperature modulation\n",
      "Dataset shape for Gas sensor temperature modulation: (36602, 3)\n",
      "Most common time difference: 0 days 00:00:30\n",
      "\n",
      "Loading dataset: ISO-NY\n",
      "File path: /Users/moji/PyTSF-MfG/data/ISO-NY_Central.csv\n",
      "Date parsing complete for ISO-NY\n",
      "Dataset shape for ISO-NY: (58324, 3)\n",
      "Most common time difference: 0 days 00:15:00\n",
      "the number of datasets: 13\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/moji/PyTSF-MfG/data/BrentOilPrices.csv')\n",
    "# Convert 'Date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='mixed')\n",
    "# Set 'Date' as the index\n",
    "df.set_index('Date', inplace=True)\n",
    "# Sort the index to ensure chronological order\n",
    "df.sort_index(inplace=True)\n",
    "# Create a complete date range including weekends\n",
    "date_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='D')\n",
    "# Reindex the dataframe with the complete date range\n",
    "df_reindexed = df.reindex(date_range)\n",
    "# Check for missing values after reindexing\n",
    "print(\"Missing values after reindexing (including weekends):\")\n",
    "print(df_reindexed.isnull().sum())\n",
    "# Interpolate missing values\n",
    "df_interpolated = df_reindexed.interpolate(method='time')\n",
    "# Check for missing values after interpolation\n",
    "print(\"\\nMissing values after interpolation:\")\n",
    "print(df_interpolated.isnull().sum())\n",
    "# Fill any remaining NaN values at the beginning or end with the nearest valid value\n",
    "df_interpolated = df_interpolated.fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "# Save the new dataset without missing values\n",
    "output_path = '/Users/moji/PyTSF-MfG/data/BrentOilPrices_Interpolated.csv'\n",
    "df_interpolated.to_csv(output_path)\n",
    "print(f\"\\nNew dataset saved as '{output_path}'\")\n",
    "\n",
    "# Display the first few rows of the interpolated dataset\n",
    "print(\"\\nFirst few rows of the interpolated dataset:\")\n",
    "print(df_interpolated.head())\n",
    "\n",
    "# Display basic statistics of the interpolated dataset\n",
    "print(\"\\nBasic statistics of the interpolated dataset:\")\n",
    "print(df_interpolated.describe())"
   ],
   "id": "8bce8c25950025bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/moji/PyTSF-MfG/data/ISO-NY_Central.csv')\n",
    "print(df.shape)\n",
    "# Convert 'Time_Stamp' column to datetime\n",
    "df['Time_Stamp'] = pd.to_datetime(df['Time_Stamp'])\n",
    "\n",
    "# Set 'Time_Stamp' as the index\n",
    "df.set_index('Time_Stamp', inplace=True)\n",
    "\n",
    "# Sort the index to ensure chronological order\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# Create a complete time range with 15-minute intervals\n",
    "time_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='15min')\n",
    "\n",
    "# Reindex the dataframe with the complete time range\n",
    "df_reindexed = df.reindex(time_range)\n",
    "print(df_reindexed.shape)\n",
    "# Check for missing values after reindexing\n",
    "print(\"Missing values after reindexing:\")\n",
    "print(df_reindexed.isnull().sum())\n",
    "# Interpolate missing values\n",
    "df_interpolated = df_reindexed.interpolate(method='time')\n",
    "# Check for missing values after interpolation\n",
    "print(\"\\nMissing values after interpolation:\")\n",
    "print(df_interpolated.isnull().sum())\n",
    "# Fill any remaining NaN values at the beginning or end with the nearest valid value\n",
    "df_interpolated = df_interpolated.fillna(method='bfill').fillna(method='ffill')\n",
    "# Final check for missing values\n",
    "print(\"\\nFinal check for missing values:\")\n",
    "print(df_interpolated.isnull().sum())\n",
    "\n",
    "# Save the new dataset without missing values\n",
    "output_path = '/Users/moji/PyTSF-MfG/data/LoadData_Interpolated.csv'\n",
    "df_interpolated.to_csv(output_path)\n",
    "\n",
    "print(f\"\\nNew dataset saved as '{output_path}'\")\n",
    "\n",
    "# Display the first few rows of the interpolated dataset\n",
    "print(\"\\nFirst few rows of the interpolated dataset:\")\n",
    "print(df_interpolated.head())\n",
    "\n",
    "# Display basic statistics of the interpolated dataset\n",
    "print(\"\\nBasic statistics of the interpolated dataset:\")\n",
    "print(df_interpolated.describe())\n",
    "# Check for any gaps in the time series\n",
    "time_diff = df_interpolated.index.to_series().diff()\n",
    "gaps = time_diff[time_diff > pd.Timedelta(minutes=15)]\n",
    "if not gaps.empty:\n",
    "    print(\"\\nGaps found in the time series:\")\n",
    "    print(gaps)\n",
    "else:\n",
    "    print(\"\\nNo gaps found in the time series.\")"
   ],
   "id": "c126774d1b692bb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "e4e1b64839e32b10",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
