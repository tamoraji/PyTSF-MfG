{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d987a662",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f4409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.utils import AirPassengersDF\n",
    "\n",
    "Y_df = AirPassengersDF # Defined in neuralforecast.utils\n",
    "Y_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82434573",
   "metadata": {},
   "source": [
    "### Important:\n",
    "* DataFrames must include all ['unique_id', 'ds', 'y'] columns. Make sure y column does not have missing or non-numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5abb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import LSTM, NHITS, RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98406e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 12\n",
    "\n",
    "# Try different hyperparmeters to improve accuracy.\n",
    "models = [LSTM(h=horizon,                    # Forecast horizon\n",
    "               max_steps=500,                # Number of steps to train\n",
    "               scaler_type='standard',       # Type of scaler to normalize data\n",
    "               encoder_hidden_size=64,       # Defines the size of the hidden state of the LSTM\n",
    "               decoder_hidden_size=64,),     # Defines the number of hidden units of each layer of the MLP decoder\n",
    "          NHITS(h=horizon,                   # Forecast horizon\n",
    "                input_size=2 * horizon,      # Length of input sequence\n",
    "                max_steps=100,               # Number of steps to train\n",
    "                n_freq_downsample=[2, 1, 1]) # Downsampling factors for each stack output\n",
    "          ]\n",
    "nf = NeuralForecast(models=models, freq='M')\n",
    "nf.fit(df=Y_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f0f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_df = nf.predict() #obtain the h forecasts after the training data Y_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24fc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0536e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_df = Y_hat_df.reset_index()\n",
    "Y_hat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b19519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b6a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (20, 7))\n",
    "plot_df = pd.concat([Y_df, Y_hat_df]).set_index('ds') # Concatenate the train and forecast dataframes\n",
    "plot_df[['y', 'LSTM', 'NHITS']].plot(ax=ax, linewidth=2)\n",
    "\n",
    "ax.set_title('AirPassengers Forecast', fontsize=22)\n",
    "ax.set_ylabel('Monthly Passengers', fontsize=20)\n",
    "ax.set_xlabel('Timestamp [t]', fontsize=20)\n",
    "ax.legend(prop={'size': 15})\n",
    "ax.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1297c0",
   "metadata": {},
   "source": [
    "## Data Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a30c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasetsforecast.m3 import M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89065072",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df, *_ = M3.load('./data', group='Yearly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df.groupby('unique_id').head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eabfe1",
   "metadata": {},
   "source": [
    "## Exogenous Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3721b5",
   "metadata": {},
   "source": [
    "* Static exogenous variables: The static exogenous variables carry time-invariant information for each time series. When the model is built with global parameters to forecast multiple time series, these variables allow sharing information within groups of time series with similar static variable levels. Examples of static variables include designators such as identifiers of regions, groups of products, etc.\n",
    "\n",
    "* Historic exogenous variables: This time-dependent exogenous variable is restricted to past observed values. Its predictive power depends on Granger-causality, as its past values can provide significant information about future values of the target variable y\n",
    "\n",
    "* Future exogenous variables: In contrast with historic exogenous variables, future values are available at the time of the prediction. Examples include calendar variables, weather forecasts, and known events that can cause large spikes and dips such as scheduled promotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf8fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/EPF_FR_BE.csv')\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad6a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(df[df['unique_id']=='FR']['ds'], df[df['unique_id']=='FR']['y'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price [EUR/MWh]')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c11973",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/EPF_FR_BE_static.csv')\n",
    "static_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7581456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.auto import NHITS, BiTCN\n",
    "from neuralforecast.core import NeuralForecast\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc50e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 24 # day-ahead daily forecast\n",
    "models = [NHITS(h = horizon,\n",
    "                input_size = 5*horizon,\n",
    "                futr_exog_list = ['gen_forecast', 'week_day'], # <- Future exogenous variables\n",
    "                hist_exog_list = ['system_load'], # <- Historical exogenous variables\n",
    "                stat_exog_list = ['market_0', 'market_1'], # <- Static exogenous variables\n",
    "                scaler_type = 'robust'),\n",
    "          BiTCN(h = horizon,\n",
    "                input_size = 5*horizon,\n",
    "                futr_exog_list = ['gen_forecast', 'week_day'], # <- Future exogenous variables\n",
    "                hist_exog_list = ['system_load'], # <- Historical exogenous variables\n",
    "                stat_exog_list = ['market_0', 'market_1'], # <- Static exogenous variables\n",
    "                scaler_type = 'robust',\n",
    "                ),                \n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ba9a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = NeuralForecast(models=models, freq='H')\n",
    "nf.fit(df=df,\n",
    "       static_df=static_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43532033",
   "metadata": {},
   "outputs": [],
   "source": [
    "futr_df = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/EPF_FR_BE_futr.csv')\n",
    "futr_df['ds'] = pd.to_datetime(futr_df['ds'])\n",
    "futr_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_df = nf.predict(futr_df=futr_df)\n",
    "Y_hat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c654104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_df = df[df['unique_id']=='FR'].tail(24*5).reset_index(drop=True)\n",
    "Y_hat_df = Y_hat_df.reset_index(drop=False)\n",
    "Y_hat_df = Y_hat_df[Y_hat_df['unique_id']=='FR']\n",
    "\n",
    "plot_df = pd.concat([plot_df, Y_hat_df ]).set_index('ds') # Concatenate the train and forecast dataframes\n",
    "\n",
    "plot_df[['y', 'NHITS', 'BiTCN']].plot(linewidth=2)\n",
    "plt.axvline('2016-11-01', color='red')\n",
    "plt.ylabel('Price [EUR/MWh]', fontsize=12)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67e7b0c",
   "metadata": {},
   "source": [
    "## Time Series Scaling\n",
    "\n",
    "The Neuralforecast library integrates two types of temporal scaling:\n",
    "\n",
    "* Time Series Scaling: scaling each time series using all its data on the train set before start training the model. This is done by using the \"local_scaler_type\" parameter of the Neuralforecast core class. local_scaler_type parameter is used to specify the type of scaling to be used. In this case, we will use standard, which scales the data to have zero mean and unit variance.Other supported scalers are minmax, robust, robust-iqr, minmax, and boxcox.\n",
    "\n",
    "* Window scaling (TemporalNorm): scaling each input window separetly for each element of the batch at every training iteration. This is done by using the \"scaler_type\" parameter of each model class. Temporal normalization is specified by the scaler_type argument. Currently, it is only supported for Windows-based models (NHITS, NBEATS, MLP, TimesNet, and all Transformers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b474560",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "The main steps of hyperparameter tuning are:\n",
    "\n",
    "* 1- Define training and validation sets.\n",
    "* 2- Define search space.\n",
    "* 3- Sample configurations with a search algorithm, train models, and evaluate them on the validation set.\n",
    "* 4- Select and store the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f31f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.utils import AirPassengersDF\n",
    "\n",
    "Y_df = AirPassengersDF\n",
    "Y_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c502ca",
   "metadata": {},
   "source": [
    "## End to End Walkthrough\n",
    "Outline:\n",
    "\n",
    "* 1- Install packages.\n",
    "* 2- Read the data.\n",
    "* 3- Explore the data.\n",
    "* 4- Train many models globally for the entire dataset.\n",
    "* 5- Evaluate the model’s performance using cross-validation.\n",
    "* 6- Select the best model for every unique time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dbd8a7",
   "metadata": {},
   "source": [
    "The input to NeuralForecast is always a data frame in long format with three columns: unique_id, ds and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Y_df = pd.read_parquet('https://datasets-nixtla.s3.amazonaws.com/m4-hourly.parquet')\n",
    "\n",
    "Y_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14a65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = Y_df['unique_id'].unique()[:10] # Select 10 ids to make the example faster\n",
    "Y_df = Y_df.query('unique_id in @uids').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast import StatsForecast\n",
    "\n",
    "StatsForecast.plot(Y_df, engine='matplotlib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.auto import AutoNHITS, AutoLSTM\n",
    "from neuralforecast.losses.pytorch import MQLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc66c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_nhits = {\n",
    "    \"input_size\": tune.choice([48, 48*2, 48*3]),              # Length of input window\n",
    "    \"start_padding_enabled\": True,\n",
    "    \"n_blocks\": 5*[1],                                              # Length of input window\n",
    "    \"mlp_units\": 5 * [[64, 64]],                                  # Length of input window\n",
    "    \"n_pool_kernel_size\": tune.choice([5*[1], 5*[2], 5*[4],         \n",
    "                                      [8, 4, 2, 1, 1]]),            # MaxPooling Kernel size\n",
    "    \"n_freq_downsample\": tune.choice([[8, 4, 2, 1, 1],\n",
    "                                      [1, 1, 1, 1, 1]]),            # Interpolation expressivity ratios\n",
    "    \"learning_rate\": tune.loguniform(1e-4, 1e-2),                   # Initial Learning rate\n",
    "    \"scaler_type\": tune.choice([None]),                             # Scaler type\n",
    "    \"max_steps\": tune.choice([1000]),                               # Max number of training iterations\n",
    "    \"batch_size\": tune.choice([1, 4, 10]),                          # Number of series in batch\n",
    "    \"windows_batch_size\": tune.choice([128, 256, 512]),             # Number of windows in batch\n",
    "    \"random_seed\": tune.randint(1, 20),                             # Random seed\n",
    "}\n",
    "\n",
    "config_lstm = {\n",
    "    \"input_size\": tune.choice([48, 48*2, 48*3]),              # Length of input window\n",
    "    \"encoder_hidden_size\": tune.choice([64, 128]),            # Hidden size of LSTM cells\n",
    "    \"encoder_n_layers\": tune.choice([2,4]),                   # Number of layers in LSTM\n",
    "    \"learning_rate\": tune.loguniform(1e-4, 1e-2),             # Initial Learning rate\n",
    "    \"scaler_type\": tune.choice(['robust']),                   # Scaler type\n",
    "    \"max_steps\": tune.choice([500, 1000]),                    # Max number of training iterations\n",
    "    \"batch_size\": tune.choice([1, 4]),                        # Number of series in batch\n",
    "    \"random_seed\": tune.randint(1, 20),                       # Random seed\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = NeuralForecast(\n",
    "    models=[\n",
    "        AutoNHITS(h=48, config=config_nhits, loss=MQLoss(), num_samples=5),\n",
    "        AutoLSTM(h=48, config=config_lstm, loss=MQLoss(), num_samples=2),\n",
    "    ],\n",
    "    freq=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c37d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf.fit(df=Y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de7ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_df = nf.predict()\n",
    "fcst_df.columns = fcst_df.columns.str.replace('-median', '')\n",
    "fcst_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f796a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to unique_ids and some selected models\n",
    "StatsForecast.plot(Y_df, fcst_df, models=[\"AutoLSTM\"], unique_ids=[\"H107\", \"H104\"], level=[80, 90], engine='matplotlib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271e9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = nf.cross_validation(Y_df, n_windows=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d64316",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.columns = cv_df.columns.str.replace('-median', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8474165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04edf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cutoff in cv_df['cutoff'].unique():\n",
    "    StatsForecast.plot(\n",
    "        Y_df, \n",
    "        cv_df.query('cutoff == @cutoff').drop(columns=['y', 'cutoff']), \n",
    "        max_insample_length=48 * 4, \n",
    "        unique_ids=['H185'],\n",
    "        engine='matplotlib'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cf0638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetsforecast.losses import mse, mae, rmse\n",
    "from datasetsforecast.evaluation import accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e371e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation_df = accuracy(cv_df, [mse, mae, rmse], agg_by=['unique_id'])\n",
    "evaluation_df['best_model'] = evaluation_df.drop(columns=['metric', 'unique_id']).idxmin(axis=1)\n",
    "evaluation_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e334a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
